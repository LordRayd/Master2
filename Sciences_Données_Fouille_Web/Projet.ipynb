{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('base': conda)",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "af0213e7f25141ee04fe389dc8ad6b35b026bad001b81753d76493b1b6cea4f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet flux Rss\n",
    "## TP 1 - Feed Collector\n",
    "### Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import shelve\n",
    "import time\n",
    "import urllib.request\n",
    "from subprocess import check_output\n",
    "\n",
    "import feedparser\n",
    "import langdetect\n",
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "source": [
    "### Item Rss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item_RSS:\n",
    "    \"\"\"\n",
    "    Représente un item Rss obtenu depuis le flux \n",
    "\n",
    "    source_feed : L url de la source du flux\n",
    "    local_url : L url du fichier local contenant la page de l'item Rss\n",
    "    lang : La langue utilisé dans le texte de l'item Rss\n",
    "    date : La date de l'item Rss\n",
    "    target_data : Le contenu de la page source de l'item Rss\n",
    "    bool_write_file : Ecrit dans des fichiers les pages des liens RSS si VRAI\n",
    "    \"\"\"\n",
    "    id = None\n",
    "    title = None\n",
    "    summary = None\n",
    "    description = None\n",
    "    all_links = None\n",
    "    source_post = None\n",
    "    source_feed = None\n",
    "    local_url = None\n",
    "    lang = None\n",
    "    date = None\n",
    "    target_data = None\n",
    "    bool_write_file = None\n",
    "\n",
    "    def __init__(self, post, feed, write_file=False, database_name='database'):\n",
    "        \"\"\"\n",
    "        Initialise l item rss a partir des données récupérés depuis le flux\n",
    "\n",
    "        Paramètres:\n",
    "            post : L'item Rss recupéré depuis le flux\n",
    "            feed : Les elements decrivants le flux\n",
    "        \"\"\"\n",
    "        if  hasattr(post, 'title'):\n",
    "            self.tile = post.title\n",
    "            self.lang = langdetect.detect(post.title)\n",
    "        if  hasattr(post, 'summary'):\n",
    "            self.summary = post.summary\n",
    "        if  hasattr(post, 'description'):\n",
    "            self.description = post.description\n",
    "        if hasattr(post, 'links'):\n",
    "            self.all_links = post.links\n",
    "        if hasattr(feed, 'link'):\n",
    "            self.source_feed = feed.link\n",
    "        self.integrity_construct()\n",
    "        if  hasattr(post, 'link'):\n",
    "            self.source_post = post.link\n",
    "            self.id = hashlib.sha224(post.link.encode(encoding='UTF-8')).hexdigest()\n",
    "            try:\n",
    "                self.local_url = './pages/' + post.link.replace('/','').replace(':','')\n",
    "                html = urllib.request.urlopen(post.link)\n",
    "                soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "                self.target_data = str(soup.prettify())\n",
    "                if self.checkIntegrity(database_name) == False and self.bool_write_file != False:\n",
    "                    self.write_target_data_In_File()\n",
    "            except urllib.error.HTTPError as e:\n",
    "                self.target_data = None\n",
    "                self.local_url = None\n",
    "            except urllib.error.URLError as e:\n",
    "                self.target_data = None\n",
    "                self.local_url = None\n",
    "\n",
    "    def affichage(self):\n",
    "        \"\"\"\n",
    "        Affiche tous les éléments de l'item Rss si ils ne sont pas vides\n",
    "        \"\"\"\n",
    "        if self.id != None:\n",
    "            print('id : ', self.id, '\\n')\n",
    "        if self.title != None:\n",
    "            print('title : ', self.title, '\\n')\n",
    "        if self.summary != None:\n",
    "            print('summary : ', self.summary, '\\n')\n",
    "        if self.description != None:\n",
    "            print('description : ', self.description, '\\n')\n",
    "        if self.source_post != None:\n",
    "            print('source_post : ', self.source_post, '\\n')\n",
    "        if self.source_feed != None:\n",
    "            print('source_feed : ', self.source_feed, '\\n')\n",
    "        if self.lang != None:\n",
    "            print('lang : ', self.lang, '\\n')\n",
    "        if self.date != None:\n",
    "            print('date : ', self.date, '\\n')\n",
    "        if self.target_data != None:\n",
    "            print('target_data : ', self.target_data, '\\n')\n",
    "\n",
    "    def write_target_data_In_File(self):\n",
    "        \"\"\"\n",
    "        Ecrit dans un fichier contenu à l'adresse local la page web qui est source de l'item Rss\n",
    "        \"\"\"\n",
    "        f = open(self.local_url, \"w\", encoding=\"utf-8\")\n",
    "        f.write(self.target_data)\n",
    "        f.close()\n",
    "\n",
    "    def integrity_construct(self):\n",
    "        \"\"\"\n",
    "        Calcul le hash qui déterminera si un element à changé au court du temps\n",
    "        \"\"\"\n",
    "        integrity = ''\n",
    "        if self.title != None:\n",
    "            integrity += self.title\n",
    "        if self.summary != None:\n",
    "            integrity += self.summary\n",
    "        if self.description != None:\n",
    "            integrity += self.description\n",
    "        if self.target_data != None:\n",
    "            integrity += self.target_data\n",
    "        self.integrity = hashlib.sha224(integrity.encode(encoding='UTF-8')).hexdigest()\n",
    "\n",
    "    def save_database(self, database_name):\n",
    "        \"\"\"\"\n",
    "        Sauvegarde l'item Rss dans la base de données\n",
    "\n",
    "        Paramètres :\n",
    "            database_name : Le nom de la base de données dans laquelle sauvegarder l'item\n",
    "        \"\"\"\n",
    "        d = shelve.open(database_name, 'c')\n",
    "        if d.__contains__(self.id) == False:\n",
    "            d[self.id] = self\n",
    "        else : \n",
    "            if self.integrity != d[self.id].integrity :\n",
    "                d[self.id] = self\n",
    "        d.close()\n",
    "\n",
    "    def checkIntegrity(self, database_name):\n",
    "        \"\"\"\"\n",
    "        Permet la vérification de l'exactitude des informations précédement enregistrer par rapport au données actuels\n",
    "\n",
    "        Paramètres :\n",
    "            database_name : Le nom de la base de données utilisé pour faire la vérification de l'intégrité\n",
    "        Retour :\n",
    "            Retourne Vrai si les données n'ont pas changé et Faux autrement\n",
    "        \"\"\"\n",
    "        ret = True\n",
    "        d = shelve.open(database_name, 'c')\n",
    "        if d.__contains__(self.id) == False:\n",
    "            ret = False\n",
    "        else : \n",
    "            if self.integrity != d[self.id].integrity :\n",
    "                ret = False\n",
    "        d.close()\n",
    "        return ret"
   ]
  },
  {
   "source": [
    "### Crawler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    nb_crawl_max = 3\n",
    "\n",
    "    def __init__(self, nb_already=0):\n",
    "        self.nb_already_done = nb_already \n",
    "\n",
    "    def crawl(self, _link):\n",
    "        if(self.nb_already_done < self.nb_crawl_max):\n",
    "            d = feedparser.parse('%s' % _link)\n",
    "            for post in d.entries:\n",
    "                elem = Item_RSS(post,d.feed)\n",
    "                for l in elem.all_links:\n",
    "                    print(l['href'])\n",
    "                    c = Crawler(self.nb_already_done + 1)\n",
    "                    c.crawl(l['href'])\n",
    "                elem.save_database('database')"
   ]
  },
  {
   "source": [
    "## TP2 - ElasticSearch\n",
    "### ElasticTool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticTool:\n",
    "\n",
    "    def connect_elasticsearch(self, _host = 'localhost', _port=9200):\n",
    "        _es = None\n",
    "        _es = Elasticsearch([{'host': _host, 'port': _port}])\n",
    "        if _es.ping():\n",
    "            print('ElasticSearch Tourne')\n",
    "        else:\n",
    "            print('ElasticSearch ne tourne pas')\n",
    "        return _es\n",
    "\n",
    "    def creation_index(self, _es):\n",
    "        _es.indices.create(index=\"item_rss\", ignore=400)\n",
    "        _es.indices.create(index=\"title\", ignore=400)\n",
    "        _es.indices.create(index=\"summary\", ignore=400)\n",
    "        _es.indices.create(index=\"description\", ignore=400)\n",
    "        _es.indices.create(index=\"all_links\", ignore=400)\n",
    "        _es.indices.create(index=\"source_post\", ignore=400)\n",
    "        _es.indices.create(index=\"lang\", ignore=400)\n",
    "        _es.indices.create(index=\"date\", ignore=400)\n",
    "        _es.indices.create(index=\"target_data\", ignore=400)\n",
    "\n",
    "    def insertion_item(self, _es, _item):\n",
    "        _es.index(index=\"item_rss\", id=_item.id, body={'item' : _item})\n",
    "        _es.index(index=\"title\", id=_item.title, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"summary\", id=_item.summary, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"description\", id=_item.description, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"all_links\", id=_item.all_links, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"source_post\", id=_item.source_post, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"lang\", id=_item.lang, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"date\", id=_item.date, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"target_data\", id=_item.target_data, body={'id_item' : _item.id})"
   ]
  },
  {
   "source": [
    "## TP 3 - Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Lancement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.cnn.com/collections/intl-obama-campaign-trail-102220/\n",
      "https://www.cnn.com/videos/politics/2020/10/21/barack-obama-full-speech-biden-philadelphia-pennsylvania-october-21-sot-vpx.cnn\n",
      "https://www.cnn.com/2020/10/21/politics/fbi-election-security/index.html\n",
      "https://www.cnn.com/2020/10/21/politics/coronavirus-lab-theory-yan-bannon-invs/index.html\n",
      "https://www.cnn.com/videos/politics/2020/10/21/coronavirus-origin-theory-steve-bannon-griffin-tsr-pkg-vpx.cnn\n",
      "https://cnn.it/3jk8RJI\n",
      "https://www.cnn.com/2020/10/22/asia/us-china-military-intl-hnk/index.html\n",
      "https://www.cnn.com/collections/intl-coronavirus-1020/\n",
      "https://www.cnn.com/2020/10/21/africa/nigeria-sars-protests-police-explainer-intl/index.html\n",
      "https://www.cnn.com/videos/politics/2020/10/21/cnn-poll-pennsylvania-florida-biden-trump-battleground-chalian-lead-sot-vpx.cnn\n",
      "https://www.cnn.com/2020/10/21/politics/melania-trump-campaign-trail-election-2020/index.html\n",
      "https://www.cnn.com/2020/10/21/politics/voting-litigation-courts-2020-election/index.html\n",
      "https://www.cnn.com/2020/10/22/media/us-china-media-company-pompeo-intl-hnk/index.html\n",
      "https://www.cnn.com/2020/10/22/politics/us-election-venezuela-trump-biden-intl/index.html\n",
      "https://www.cnn.com/2020/10/22/asia/thailand-protests-state-of-emergency-intl-hnk/index.html\n",
      "https://www.cnn.com/2020/10/21/politics/barrett-school-lgbtq/index.html\n",
      "https://edition.cnn.com/interactive/2020/10/world/coronavirus-impact-domestic-abuse-global/\n",
      "https://www.cnn.com/videos/world/2020/10/21/vietnam-floods-lon-orig-tp.cnn\n",
      "https://www.cnn.com/2020/10/22/world/black-media-representation-bhm-gbr-intl/index.html\n",
      "https://www.cnn.com/2020/10/21/asia/japan-women-politics-hnk-dst-intl/index.html\n",
      "https://www.cnn.com/2020/10/21/health/new-organ-throat-scn-wellness/index.html\n",
      "https://www.cnn.com/videos/politics/2020/10/16/undecided-voters-ohio-election-2020-mh-jm-orig.cnn\n",
      "https://www.cnn.com/2020/10/21/politics/taiwan-arms-sales-formal-notification/index.html\n",
      "https://www.cnn.com/2020/10/21/tech/google-antitrust-lawsuit-better-search/index.html\n",
      "https://www.cnn.com/videos/world/2020/10/21/nigeria-lagos-sars-protests-busari-pkg-ctw-intl-ldn-vpx.cnn\n",
      "https://www.cnn.com/2020/10/22/tech/ant-group-ipo-intl-hnk/index.html\n",
      "https://www.cnn.com/2020/10/21/tech/tesla-earnings/index.html\n",
      "https://www.cnn.com/2020/10/22/football/marcus-rashford-lawmakers-free-school-meals-spt-intl/index.html\n",
      "https://www.cnn.com/videos/health/2020/10/21/astrazeneca-vaccine-trial-volunteer-dies-gupta-nr-vpx.cnn\n",
      "https://www.cnn.com/2020/10/22/sport/ysaora-thibus-fencer-cmd-spt-intl/index.html\n",
      "https://www.cnn.com/videos/politics/2020/10/21/intv-amanpour-election-black-women-martha-s-jones-xernona-clayton.cnn\n",
      "https://www.cnn.com/2020/10/22/health/divorce-separation-covid-19-pandemic-wellness/index.html\n",
      "https://www.cnn.com/videos/tv/2020/10/21/staying-well-bilingual-brain-for-wellness.cnn\n",
      "https://www.cnn.com/travel/article/caspian-sea-monster-ekranoplan/index.html\n",
      "https://www.cnn.com/travel/article/us-hong-kong-covid-travel-intl-hnk/index.html\n",
      "https://www.cnn.com/2020/10/21/media/quibi-shutting-down/index.html\n",
      "https://www.cnn.com/videos/entertainment/2020/10/21/reese-witherspoon-legally-blonde-mxp-vpx.hln\n",
      "https://www.cnn.com/2020/10/21/world/nasa-asteroid-bennu-new-images-scn-trnd/index.html\n",
      "https://www.cnn.com/videos/world/2020/10/21/egyptian-police-cadet-graduation-ceremony-newsource-orig-vpx.cnn\n",
      "https://www.cnn.com/style/article/giacometti-grande-femme-sothebys-secret-bids/index.html\n",
      "https://www.cnn.com/videos/media/2020/10/21/dolly-parton-makes-stephen-colbert-cry-orig-vstan-bdk.cnn\n",
      "https://www.cnn.com/2020/10/22/health/knee-strengthening-exercises-wellness/index.html\n",
      "https://www.cnn.com/videos/business/2020/10/22/first-firefighting-robot-in-america-lafd-trnd-no-orig.cnn\n",
      "https://www.cnn.com/2020/10/22/politics/election-2020-donald-trump-barack-obama-joe-biden-swing-states/index.html\n",
      "https://www.cnn.com/videos/politics/2020/10/21/barack-obama-biden-speech-superman-is-back-in-the-building-van-jones-sot-tsr-vpx.cnn\n",
      "https://www.cnn.com/2020/10/21/politics/joe-biden-outspending-donald-trump-tv/index.html\n",
      "https://www.cnn.com/2020/10/21/politics/trump-coronavirus-bolling/index.html\n",
      "https://www.cnn.com/2020/10/22/europe/europe-coronavirus-older-people-intl/index.html\n",
      "https://www.cnn.com/2020/10/21/world/meanwhile-in-america-october-21-intl/index.html\n"
     ]
    }
   ],
   "source": [
    "cr = Crawler()\n",
    "cr.crawl(\"http://rss.cnn.com/rss/edition.rss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}