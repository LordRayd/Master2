{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit (conda)",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "af0213e7f25141ee04fe389dc8ad6b35b026bad001b81753d76493b1b6cea4f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet flux Rss\n",
    "## TP 1 - Feed Collector\n",
    "### Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import shelve\n",
    "import time\n",
    "import urllib.request\n",
    "from subprocess import check_output\n",
    "from datetime import datetime\n",
    "\n",
    "import feedparser\n",
    "import langdetect\n",
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "source": [
    "### Item Rss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item_RSS:\n",
    "    \"\"\"\n",
    "    Représente un item Rss obtenu depuis le flux \n",
    "\n",
    "    source_feed : L url de la source du flux\n",
    "    local_url : L url du fichier local contenant la page de l'item Rss\n",
    "    lang : La langue utilisé dans le texte de l'item Rss\n",
    "    date : La date de l'item Rss\n",
    "    target_data : Le contenu de la page source de l'item Rss\n",
    "    \"\"\"\n",
    "    id = None\n",
    "    title = None\n",
    "    summary = None\n",
    "    description = None\n",
    "    all_links = None\n",
    "    source_post = None\n",
    "    source_feed = None\n",
    "    lang = None\n",
    "    date = None\n",
    "    target_data = None\n",
    "\n",
    "    def __init__(self, post, feed, tool=None):\n",
    "        \"\"\"\n",
    "        Initialise l item rss a partir des données récupérés depuis le flux\n",
    "\n",
    "        Paramètres:\n",
    "            post : L'item Rss recupéré depuis le flux\n",
    "            feed : Les elements decrivants le flux\n",
    "        \"\"\"\n",
    "        self.tool = tool\n",
    "        if  hasattr(post, 'title'):\n",
    "            self.tile = post.title\n",
    "            self.lang = langdetect.detect(post.title)\n",
    "        if  hasattr(post, 'summary'):\n",
    "            self.summary = post.summary\n",
    "        if  hasattr(post, 'description'):\n",
    "            self.description = post.description\n",
    "        if hasattr(post, 'links'):\n",
    "            self.all_links = post.links\n",
    "        if hasattr(feed, 'link'):\n",
    "            self.source_feed = feed.link\n",
    "        self.integrity_construct()\n",
    "        if  hasattr(post, 'link'):\n",
    "            self.source_post = post.link\n",
    "            self.id = hashlib.sha224(post.link.encode(encoding='UTF-8')).hexdigest()\n",
    "            try:\n",
    "                html = urllib.request.urlopen(post.link)\n",
    "                soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "                self.target_data = str(soup.prettify())\n",
    "            except urllib.error.HTTPError as e:\n",
    "                self.target_data = None\n",
    "            except urllib.error.URLError as e:\n",
    "                self.target_data = None\n",
    "        self.date = datetime.now()\n",
    "\n",
    "    def affichage(self):\n",
    "        \"\"\"\n",
    "        Affiche tous les éléments de l'item Rss si ils ne sont pas vides\n",
    "        \"\"\"\n",
    "        self.print_id()\n",
    "        self.print_title()\n",
    "        self.print_summary()\n",
    "        self.print_description()\n",
    "        self.print_source_post()\n",
    "        self.print_source_feed()\n",
    "        self.print_lang()\n",
    "        self.print_date()\n",
    "        self.print_target_data()\n",
    "    \n",
    "    def print_id(self):\n",
    "        if self.id != None:\n",
    "            print('id : ', self.id, '\\n')\n",
    "    def print_title(self) :\n",
    "        if self.title != None:\n",
    "            print('title : ', self.title, '\\n')\n",
    "    def print_summary(self) : \n",
    "        if self.summary != None:\n",
    "            print('summary : ', self.summary, '\\n')\n",
    "    def print_description(self) : \n",
    "        if self.description != None:\n",
    "            print('description : ', self.description, '\\n')\n",
    "    def print_source_post(self) : \n",
    "        if self.source_post != None:\n",
    "            print('source_post : ', self.source_post, '\\n')\n",
    "    def print_source_feed(self) :\n",
    "        if self.source_feed != None:\n",
    "            print('source_feed : ', self.source_feed, '\\n')\n",
    "    def print_lang(self) : \n",
    "        if self.lang != None:\n",
    "            print('lang : ', self.lang, '\\n')\n",
    "    def print_date(self) :\n",
    "        if self.date != None:\n",
    "            print('date : ', self.date, '\\n')\n",
    "    def print_target_data(self) : \n",
    "        if self.target_data != None:\n",
    "            print('target_data : ', self.target_data, '\\n')\n",
    "\n",
    "    def integrity_construct(self):\n",
    "        \"\"\"\n",
    "        Calcul le hash qui déterminera si un element à changé au court du temps\n",
    "        \"\"\"\n",
    "        integrity = ''\n",
    "        if self.title != None:\n",
    "            integrity += self.title\n",
    "        if self.summary != None:\n",
    "            integrity += self.summary\n",
    "        if self.description != None:\n",
    "            integrity += self.description\n",
    "        if self.target_data != None:\n",
    "            integrity += self.target_data\n",
    "        self.integrity = hashlib.sha224(integrity.encode(encoding='UTF-8')).hexdigest()\n",
    "\n",
    "    def save(self):\n",
    "        if self.tool != None :\n",
    "            self.tool.insertion_item(self)\n",
    "            self.tool.verification_integrity(self.id, self.integrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database_Tool:\n",
    "\n",
    "    _db = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self._db = self.getConnection()\n",
    "\n",
    "    def getConnection(self, database_name='database'):\n",
    "        return shelve.open(self.database_name, 'c')\n",
    "\n",
    "    def insertion_items(self, _items) :\n",
    "        for i in _items :\n",
    "            self.insertion_item(i)\n",
    "\n",
    "    def insertion_item(self, _item): \n",
    "        if self._db.__contains__(_item.id) == False:\n",
    "            self._db[_item.id] = _item\n",
    "        else : \n",
    "            if _item.integrity != self._db[_item.id].integrity :\n",
    "                self._db[_item.id] = _item\n",
    "\n",
    "    def verification_integrity(self, id_, integrity_):\n",
    "        ret = True\n",
    "        if self._db.__contains__(id_) == False:\n",
    "            ret = False\n",
    "        else : \n",
    "            if integrity_ != self._db[id_].integrity :\n",
    "                ret = False\n",
    "        return ret"
   ]
  },
  {
   "source": [
    "### Crawler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    nb_crawl_max = 1\n",
    "\n",
    "    def __init__(self, nb_already=0, _save_tool=1):\n",
    "        self.nb_already_done = nb_already\n",
    "        self.save_tool = _save_tool\n",
    "        if self.save_tool == 0 : \n",
    "            self.tool = Database_Tool()\n",
    "        else : \n",
    "            self.tool = ElasticTool()\n",
    "\n",
    "    def crawl(self, _link):\n",
    "        if(self.nb_already_done < self.nb_crawl_max):\n",
    "            d = feedparser.parse('%s' % _link)\n",
    "            for post in d.entries:\n",
    "                elem = Item_RSS(post,d.feed, tool=self.tool)\n",
    "                for l in elem.all_links:\n",
    "                    c = Crawler(self.nb_already_done + 1, _save_tool=self.save_tool)\n",
    "                    c.crawl(l['href'])\n",
    "                elem.save()"
   ]
  },
  {
   "source": [
    "## TP2 - ElasticSearch\n",
    "### ElasticTool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticTool:\n",
    "\n",
    "    _es = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._es = self.getConnection()\n",
    "        self.add_all_index()\n",
    "\n",
    "    def getConnection(self, _host = 'localhost', _port=9200):\n",
    "        if self._es == None :\n",
    "            self._es = Elasticsearch([{'host': _host, 'port': _port}])\n",
    "        return self._es\n",
    "\n",
    "    def add_index(self, name_index):\n",
    "        if self._es.indices.exists(index=name_index):\n",
    "            self._es.indices.create(index=name_index, ignore=400)\n",
    "\n",
    "    def add_all_index(self):\n",
    "        self.add_index(\"item_rss\")\n",
    "        self.add_index(\"title\")\n",
    "        self.add_index(\"summary\")\n",
    "        self.add_index(\"description\")\n",
    "        self.add_index(\"links\")\n",
    "        self.add_index(\"source_post\")\n",
    "        self.add_index(\"lang\")\n",
    "        self.add_index(\"date\")\n",
    "        self.add_index(\"target_data\")\n",
    "        self.add_index('integrity')\n",
    "\n",
    "    def delete_index(self, name_index):\n",
    "        self._es.indices.delete(index=name_index, ignore=[400, 404])\n",
    "\n",
    "    def delete_all_index(self):\n",
    "        self.delete_index(\"item_rss\")\n",
    "        self.delete_index(\"title\")\n",
    "        self.delete_index(\"summary\")\n",
    "        self.delete_index(\"description\")\n",
    "        self.delete_index(\"links\")\n",
    "        self.delete_index(\"source_post\")\n",
    "        self.delete_index(\"lang\")\n",
    "        self.delete_index(\"date\")\n",
    "        self.delete_index(\"target_data\")\n",
    "        self.delete_index('integrity')\n",
    "\n",
    "    def insertion_all_items(self, _items):\n",
    "        for i in _items :\n",
    "            self.insertion_item(i)\n",
    "\n",
    "    def insertion_item(self, _item):\n",
    "        if self.verification_integrity(_item.id, _item.integrity) == False :\n",
    "            id_title = self.save_title(_item)\n",
    "            id_summary = self.save_summary(_item)\n",
    "            id_description = self.save_description(_item)\n",
    "            id_all_links = self.save_all_links(_item)\n",
    "            id_source_post = self.save_source_post(_item)\n",
    "            id_lang = self.save_lang(_item)\n",
    "            id_date = self.save_date(_item)\n",
    "            id_target_data = False #self.save_target_data(_item)\n",
    "            id_integrity = self.save_integrity(_item)\n",
    "            self.save_item(_item.id, id_title, id_summary, id_description, id_all_links, id_source_post, id_lang, id_date, id_target_data, id_integrity)\n",
    "\n",
    "    def save_item(self, _id, _title, _summary, _description, _all_links, _source_post, _lang, _date, _target_data, _integrity):\n",
    "        content_body = {}\n",
    "        if _title != False :\n",
    "            content_body['id_title'] = _title\n",
    "        if _summary != False :\n",
    "            content_body['id_summary'] = _summary\n",
    "        if _description != False :\n",
    "            content_body['id_description'] = _description\n",
    "        if _all_links != False :\n",
    "            content_body['id_all_links'] = _all_links\n",
    "        if _source_post != False :\n",
    "            content_body['id_source_post'] = _source_post\n",
    "        if _lang != False :\n",
    "            content_body['id_lang'] = _lang\n",
    "        if _date != False :\n",
    "            content_body['id_date'] = _date\n",
    "        if _target_data != False :\n",
    "            content_body['id_target_data'] = _target_data\n",
    "        if _integrity != False :\n",
    "            content_body['id_integrity'] = _integrity\n",
    "        self._es.index(index='item_rss', id=_id, body=content_body)\n",
    "\n",
    "    def save_title(self, _item) : \n",
    "        if(_item.title != None) : \n",
    "            content_body = {\n",
    "                'value' : _item.title,\n",
    "                'tags' : _item.title.split(' '),\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"title\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_summary(self, _item):\n",
    "        if _item.summary != None :\n",
    "            content_body = {\n",
    "                'value' : _item.summary,\n",
    "                'tags' : _item.summary.split(' '),\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"summary\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_description(self, _item):\n",
    "        if _item.description != None :\n",
    "            content_body = {\n",
    "                'value' : _item.description,\n",
    "                'tags' : _item.description.split(' '),\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"description\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_link(self, _link, _id):\n",
    "        content_body = {\n",
    "            'value' : _link,\n",
    "            'id_item' : _id\n",
    "        }\n",
    "        return self._es.index(index=\"links\", body=content_body)['_id']\n",
    "\n",
    "    def save_all_links(self,_item):\n",
    "        id_tab_links = []\n",
    "        if(_item.all_links != None):\n",
    "            for l in _item.all_links:\n",
    "                id_tab_links.append(self.save_link(l, _item.id))\n",
    "        return id_tab_links if len(id_tab_links)>0 else False\n",
    "\n",
    "    def save_source_post(self, _item):\n",
    "        if _item.source_post != None :\n",
    "            content_body = {\n",
    "                'value' : _item.source_post,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"source_post\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_lang(self, _item):\n",
    "        if _item.source_post != None :\n",
    "            content_body = {\n",
    "                'value' : _item.lang,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"lang\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_date(self, _item):\n",
    "        if _item.date != None :\n",
    "            content_body = {\n",
    "                'value' : _item.date,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"date\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_target_data(self, _item):\n",
    "        if _item.target_data != None :\n",
    "            content_body = {\n",
    "                'value' : _item.target_data,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"target_data\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_integrity(self, _item):\n",
    "        if _item.integrity != None :\n",
    "            content_body = {\n",
    "                'value' : _item.integrity,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"integrity\", body=content_body)['_id']\n",
    "        return False\n",
    "        \n",
    "    def search_by_tags(self, index_name, tags, size_result=999):\n",
    "        \n",
    "        str_query = ''\n",
    "        maxi = len(tags)\n",
    "        for i in range(maxi):\n",
    "            str_query += 'tags:' + tags[i]\n",
    "            if i < maxi-1:\n",
    "                str_query += ' AND '\n",
    "                \n",
    "        query_body ={\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                    \"query\" : str_query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return self._es.search(index=index_name, body=query_body, size=size_result)\n",
    "\n",
    "    def verification_integrity(self, id_, integrity_):\n",
    "        res = self._es.get(index=\"integrity\", id=id_, ignore=[400,404])\n",
    "        return False"
   ]
  },
  {
   "source": [
    "## TP 3 - Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'error': {'root_cause': [{'type': 'index_not_found_exception',\n",
       "    'reason': 'no such index [integrity]',\n",
       "    'resource.type': 'index_expression',\n",
       "    'resource.id': 'integrity',\n",
       "    'index_uuid': '_na_',\n",
       "    'index': 'integrity'}],\n",
       "  'type': 'index_not_found_exception',\n",
       "  'reason': 'no such index [integrity]',\n",
       "  'resource.type': 'index_expression',\n",
       "  'resource.id': 'integrity',\n",
       "  'index_uuid': '_na_',\n",
       "  'index': 'integrity'},\n",
       " 'status': 404}"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "elastic_tool._es.get(index=\"integrity\", id='al3LrnUB1UJFcz4jJfEM', ignore=[400,404])"
   ]
  },
  {
   "source": [
    "## Lancement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cr = Crawler()\n",
    "cr.crawl(\"https://www.lefigaro.fr/rss/figaro_economie.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 0, 'relation': 'eq'},\n",
       "  'max_score': None,\n",
       "  'hits': []}}"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "elastic_tool = ElasticTool()\n",
    "elastic_tool.search_by_tags('description',['commerces'])\n",
    "elastic_tool.search_by_tags('description', ['commerces', 'rouvrir', 'pouvoir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_tool = ElasticTool()\n",
    "elastic_tool.delete_all_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "\n",
    "links = [link.rstrip('\\n').split(' ') for link in fileinput.input(files=('rss.txt'))]\n",
    "for link,*subjects in links:\n",
    "    pass"
   ]
  }
 ]
}