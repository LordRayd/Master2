{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('base': conda)",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "af0213e7f25141ee04fe389dc8ad6b35b026bad001b81753d76493b1b6cea4f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet flux Rss\n",
    "## TP 1 - Feed Collector\n",
    "### Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import shelve\n",
    "import time\n",
    "import urllib.request\n",
    "from subprocess import check_output\n",
    "\n",
    "import feedparser\n",
    "import langdetect\n",
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "source": [
    "### Item Rss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item_RSS:\n",
    "    \"\"\"\n",
    "    Représente un item Rss obtenu depuis le flux \n",
    "    \"\"\"\n",
    "    id = None\n",
    "    \"\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    title = None\n",
    "    \"\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    summary = None\n",
    "    \"\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    description = None\n",
    "    \"\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    all_links = None\n",
    "    \"\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    source_post = None\n",
    "    \"\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    source_feed = None\n",
    "    \"\"\"\"\n",
    "    L url de la source du flux\n",
    "    \"\"\"\n",
    "    local_url = None\n",
    "    \"\"\"\"\n",
    "    l url du fichier local contenant la page de l'item Rss\n",
    "    \"\"\"\n",
    "    lang = None\n",
    "    \"\"\"\n",
    "    La langue utilisé dans le texte de l'item Rss\n",
    "    \"\"\"\n",
    "    date = None\n",
    "    \"\"\"\"\n",
    "    La date de l'item Rss\n",
    "    \"\"\"\n",
    "    target_data = None\n",
    "    \"\"\"\"\n",
    "    Le contenu de la page source de l'item Rss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, post, feed, database_name='database'):\n",
    "        \"\"\"\n",
    "        Initialise l item rss a partir des données récupérés depuis le flux\n",
    "\n",
    "        Paramètres:\n",
    "            post : L'item Rss recupéré depuis le flux\n",
    "            feed : Les elements decrivants le flux\n",
    "        \"\"\"\n",
    "        if  hasattr(post, 'title'):\n",
    "            self.tile = post.title\n",
    "            self.lang = langdetect.detect(post.title)\n",
    "        if  hasattr(post, 'summary'):\n",
    "            self.summary = post.summary\n",
    "        if  hasattr(post, 'description'):\n",
    "            self.description = post.description\n",
    "        if hasattr(post, 'links'):\n",
    "            self.all_links = post.links\n",
    "        if hasattr(feed, 'link'):\n",
    "            self.source_feed = feed.link\n",
    "        self.integrity_construct()\n",
    "        if  hasattr(post, 'link'):\n",
    "            self.source_post = post.link\n",
    "            self.id = hashlib.sha224(post.link.encode(encoding='UTF-8')).hexdigest()\n",
    "            try:\n",
    "                self.local_url = './pages/' + post.link.replace('/','').replace(':','')\n",
    "                html = urllib.request.urlopen(post.link)\n",
    "                soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "                self.target_data = str(soup.prettify())\n",
    "                if self.checkIntegrity(database_name) == False :\n",
    "                    self.write_target_data_In_File()\n",
    "            except urllib.error.HTTPError as e:\n",
    "                self.target_data = None\n",
    "                self.local_url = None\n",
    "            except urllib.error.URLError as e:\n",
    "                self.target_data = None\n",
    "                self.local_url = None\n",
    "\n",
    "    def affichage(self):\n",
    "        \"\"\"\n",
    "        Affiche tous les éléments de l'item Rss si ils ne sont pas vides\n",
    "        \"\"\"\n",
    "        if self.id != None:\n",
    "            print('id : ', self.id, '\\n')\n",
    "        if self.title != None:\n",
    "            print('title : ', self.title, '\\n')\n",
    "        if self.summary != None:\n",
    "            print('summary : ', self.summary, '\\n')\n",
    "        if self.description != None:\n",
    "            print('description : ', self.description, '\\n')\n",
    "        if self.source_post != None:\n",
    "            print('source_post : ', self.source_post, '\\n')\n",
    "        if self.source_feed != None:\n",
    "            print('source_feed : ', self.source_feed, '\\n')\n",
    "        if self.lang != None:\n",
    "            print('lang : ', self.lang, '\\n')\n",
    "        if self.date != None:\n",
    "            print('date : ', self.date, '\\n')\n",
    "        if self.target_data != None:\n",
    "            print('target_data : ', self.target_data, '\\n')\n",
    "\n",
    "    def write_target_data_In_File(self):\n",
    "        \"\"\"\n",
    "        Ecrit dans un fichier contenu à l'adresse local la page web qui est source de l'item Rss\n",
    "        \"\"\"\n",
    "        f = open(self.local_url, \"w\", encoding=\"utf-8\")\n",
    "        f.write(self.target_data)\n",
    "        f.close()\n",
    "\n",
    "    def integrity_construct(self):\n",
    "        \"\"\"\n",
    "        Calcul le hash qui déterminera si un element à changé au court du temps\n",
    "        \"\"\"\n",
    "        integrity = ''\n",
    "        if self.title != None:\n",
    "            integrity += self.title\n",
    "        if self.summary != None:\n",
    "            integrity += self.summary\n",
    "        if self.description != None:\n",
    "            integrity += self.description\n",
    "        if self.target_data != None:\n",
    "            integrity += self.target_data\n",
    "        self.integrity = hashlib.sha224(integrity.encode(encoding='UTF-8')).hexdigest()\n",
    "\n",
    "    def save_database(self, database_name):\n",
    "        \"\"\"\"\n",
    "        Sauvegarde l'item Rss dans la base de données\n",
    "\n",
    "        Paramètres :\n",
    "            database_name : Le nom de la base de données dans laquelle sauvegarder l'item\n",
    "        \"\"\"\n",
    "        d = shelve.open(database_name, 'c')\n",
    "        if d.__contains__(self.id) == False:\n",
    "            d[self.id] = self\n",
    "        else : \n",
    "            if self.integrity != d[self.id].integrity :\n",
    "                d[self.id] = self\n",
    "        d.close()\n",
    "\n",
    "    def checkIntegrity(self, database_name):\n",
    "        \"\"\"\"\n",
    "        Permet la vérification de l'exactitude des informations précédement enregistrer par rapport au données actuels\n",
    "\n",
    "        Paramètres :\n",
    "            database_name : Le nom de la base de données utilisé pour faire la vérification de l'intégrité\n",
    "        Retour :\n",
    "            Retourne Vrai si les données n'ont pas changé et Faux autrement\n",
    "        \"\"\"\n",
    "        ret = True\n",
    "        d = shelve.open(database_name, 'c')\n",
    "        if d.__contains__(self.id) == False:\n",
    "            ret = False\n",
    "        else : \n",
    "            if self.integrity != d[self.id].integrity :\n",
    "                ret = False\n",
    "        d.close()\n",
    "        return ret"
   ]
  },
  {
   "source": [
    "### Crawler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    nb_crawl_max = 1\n",
    "\n",
    "    def __init__(self, nb_already=0):\n",
    "        self.nb_already_done = nb_already \n",
    "\n",
    "    def crawl(self, _link):\n",
    "        if(self.nb_already_done < self.nb_crawl_max):\n",
    "            d = feedparser.parse(\"http://rss.cnn.com/rss/edition.rss\")\n",
    "            for post in d.entries:\n",
    "                elem = Item_RSS(post,d.feed)\n",
    "                elem.save_database('database')\n",
    "                for l in elem.all_links:\n",
    "                    c = Crawler(self.nb_already_done + 1)\n",
    "                    c.crawl(l)"
   ]
  },
  {
   "source": [
    "## TP2 - ElasticSearch\n",
    "### ElasticTool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticTool:\n",
    "\n",
    "    def connect_elasticsearch(self, _host = 'localhost', _port=9200):\n",
    "        _es = None\n",
    "        _es = Elasticsearch([{'host': _host, 'port': _port}])\n",
    "        if _es.ping():\n",
    "            print('ElasticSearch Tourne')\n",
    "        else:\n",
    "            print('ElasticSearch ne tourne pas')\n",
    "        return _es\n",
    "\n",
    "    def creation_index(self, _es):\n",
    "        _es.indices.create(index=\"item_rss\", ignore=400)\n",
    "        _es.indices.create(index=\"title\", ignore=400)\n",
    "        _es.indices.create(index=\"summary\", ignore=400)\n",
    "        _es.indices.create(index=\"description\", ignore=400)\n",
    "        _es.indices.create(index=\"all_links\", ignore=400)\n",
    "        _es.indices.create(index=\"source_post\", ignore=400)\n",
    "        _es.indices.create(index=\"lang\", ignore=400)\n",
    "        _es.indices.create(index=\"date\", ignore=400)\n",
    "        _es.indices.create(index=\"target_data\", ignore=400)\n",
    "\n",
    "    def insertion_item(self, _es, _item):\n",
    "        _es.index(index=\"item_rss\", id=_item.id, body={'item' : _item})\n",
    "        _es.index(index=\"title\", id=_item.title, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"summary\", id=_item.summary, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"description\", id=_item.description, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"all_links\", id=_item.all_links, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"source_post\", id=_item.source_post, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"lang\", id=_item.lang, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"date\", id=_item.date, body={'id_item' : _item.id})\n",
    "        _es.index(index=\"target_data\", id=_item.target_data, body={'id_item' : _item.id})"
   ]
  },
  {
   "source": [
    "## TP 3 - Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Lancement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pages/httpswww.cnn.comvideospolitics20201021barack-obama-full-speech-biden-philadelphia-pennsylvania-october-21-sot-vpx.cnn'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9b9ed0fe52ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://rss.cnn.com/rss/edition.rss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-bd6cfeef0a73>\u001b[0m in \u001b[0;36mcrawl\u001b[1;34m(self, _link)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://rss.cnn.com/rss/edition.rss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 \u001b[0melem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mItem_RSS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'database'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_links\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-40030f92127e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, post, feed, database_name)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckIntegrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_target_data_In_File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-40030f92127e>\u001b[0m in \u001b[0;36mwrite_target_data_In_File\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mEcrit\u001b[0m \u001b[0mdans\u001b[0m \u001b[0mun\u001b[0m \u001b[0mfichier\u001b[0m \u001b[0mcontenu\u001b[0m \u001b[0mà\u001b[0m \u001b[0ml\u001b[0m\u001b[1;34m'adresse local la page web qui est source de l'\u001b[0m\u001b[0mitem\u001b[0m \u001b[0mRss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pages/httpswww.cnn.comvideospolitics20201021barack-obama-full-speech-biden-philadelphia-pennsylvania-october-21-sot-vpx.cnn'"
     ]
    }
   ],
   "source": [
    "cr = Crawler()\n",
    "cr.crawl(\"http://rss.cnn.com/rss/edition.rss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}