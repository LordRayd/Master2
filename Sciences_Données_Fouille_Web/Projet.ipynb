{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit (conda)",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "af0213e7f25141ee04fe389dc8ad6b35b026bad001b81753d76493b1b6cea4f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet flux Rss\n",
    "## TP 1 - Feed Collector\n",
    "### Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import shelve\n",
    "import time\n",
    "import urllib.request\n",
    "from subprocess import check_output\n",
    "from datetime import datetime\n",
    "\n",
    "import feedparser\n",
    "import langdetect\n",
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "source": [
    "### Item Rss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item_RSS:\n",
    "    \"\"\"\n",
    "    Représente un item Rss obtenu depuis le flux \n",
    "\n",
    "    source_feed : L url de la source du flux\n",
    "    local_url : L url du fichier local contenant la page de l'item Rss\n",
    "    lang : La langue utilisé dans le texte de l'item Rss\n",
    "    date : La date de l'item Rss\n",
    "    target_data : Le contenu de la page source de l'item Rss\n",
    "    bool_write_file : Ecrit dans des fichiers les pages des liens RSS si VRAI\n",
    "    \"\"\"\n",
    "    id = None\n",
    "    title = None\n",
    "    summary = None\n",
    "    description = None\n",
    "    all_links = None\n",
    "    source_post = None\n",
    "    source_feed = None\n",
    "    local_url = None\n",
    "    lang = None\n",
    "    date = None\n",
    "    target_data = None\n",
    "\n",
    "    def __init__(self, post, feed, write_file=False, database_name=None,elastic_connection=None):\n",
    "        \"\"\"\n",
    "        Initialise l item rss a partir des données récupérés depuis le flux\n",
    "\n",
    "        Paramètres:\n",
    "            post : L'item Rss recupéré depuis le flux\n",
    "            feed : Les elements decrivants le flux\n",
    "        \"\"\"\n",
    "        self.elastic_connection = elastic_connection\n",
    "        self.database_name = database_name\n",
    "        if  hasattr(post, 'title'):\n",
    "            self.tile = post.title\n",
    "            self.lang = langdetect.detect(post.title)\n",
    "        if  hasattr(post, 'summary'):\n",
    "            self.summary = post.summary\n",
    "        if  hasattr(post, 'description'):\n",
    "            self.description = post.description\n",
    "        if hasattr(post, 'links'):\n",
    "            self.all_links = post.links\n",
    "        if hasattr(feed, 'link'):\n",
    "            self.source_feed = feed.link\n",
    "        self.integrity_construct()\n",
    "        if  hasattr(post, 'link'):\n",
    "            self.source_post = post.link\n",
    "            self.id = hashlib.sha224(post.link.encode(encoding='UTF-8')).hexdigest()\n",
    "            try:\n",
    "                self.local_url = './pages/' + post.link.replace('/','').replace(':','')\n",
    "                html = urllib.request.urlopen(post.link)\n",
    "                soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "                self.target_data = str(soup.prettify())\n",
    "                if self.checkIntegrity() == False and write_file != False:\n",
    "                    self.write_target_data_In_File()\n",
    "            except urllib.error.HTTPError as e:\n",
    "                self.target_data = None\n",
    "                self.local_url = None\n",
    "            except urllib.error.URLError as e:\n",
    "                self.target_data = None\n",
    "                self.local_url = None\n",
    "        self.date = datetime.now()\n",
    "        self.save_elastic()\n",
    "\n",
    "    def affichage(self):\n",
    "        \"\"\"\n",
    "        Affiche tous les éléments de l'item Rss si ils ne sont pas vides\n",
    "        \"\"\"\n",
    "        self.print_id()\n",
    "        self.print_title()\n",
    "        self.print_summary()\n",
    "        self.print_description()\n",
    "        self.print_source_post()\n",
    "        self.print_source_feed()\n",
    "        self.print_lang()\n",
    "        self.print_date()\n",
    "        self.print_target_data()\n",
    "    \n",
    "    def print_id(self):\n",
    "        if self.id != None:\n",
    "            print('id : ', self.id, '\\n')\n",
    "    def print_title(self) :\n",
    "        if self.title != None:\n",
    "            print('title : ', self.title, '\\n')\n",
    "    def print_summary(self) : \n",
    "        if self.summary != None:\n",
    "            print('summary : ', self.summary, '\\n')\n",
    "    def print_description(self) : \n",
    "        if self.description != None:\n",
    "            print('description : ', self.description, '\\n')\n",
    "    def print_source_post(self) : \n",
    "        if self.source_post != None:\n",
    "            print('source_post : ', self.source_post, '\\n')\n",
    "    def print_source_feed(self) :\n",
    "        if self.source_feed != None:\n",
    "            print('source_feed : ', self.source_feed, '\\n')\n",
    "    def print_lang(self) : \n",
    "        if self.lang != None:\n",
    "            print('lang : ', self.lang, '\\n')\n",
    "    def print_date(self) :\n",
    "        if self.date != None:\n",
    "            print('date : ', self.date, '\\n')\n",
    "    def print_target_data(self) : \n",
    "        if self.target_data != None:\n",
    "            print('target_data : ', self.target_data, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def write_target_data_In_File(self):\n",
    "        \"\"\"\n",
    "        Ecrit dans un fichier contenu à l'adresse local la page web qui est source de l'item Rss\n",
    "        \"\"\"\n",
    "        f = open(self.local_url, \"w\", encoding=\"utf-8\")\n",
    "        f.write(self.target_data)\n",
    "        f.close()\n",
    "\n",
    "    def integrity_construct(self):\n",
    "        \"\"\"\n",
    "        Calcul le hash qui déterminera si un element à changé au court du temps\n",
    "        \"\"\"\n",
    "        integrity = ''\n",
    "        if self.title != None:\n",
    "            integrity += self.title\n",
    "        if self.summary != None:\n",
    "            integrity += self.summary\n",
    "        if self.description != None:\n",
    "            integrity += self.description\n",
    "        if self.target_data != None:\n",
    "            integrity += self.target_data\n",
    "        self.integrity = hashlib.sha224(integrity.encode(encoding='UTF-8')).hexdigest()\n",
    "\n",
    "    def save_database(self):\n",
    "        \"\"\"\"\n",
    "        Sauvegarde l'item Rss dans la base de données\n",
    "\n",
    "        Paramètres :\n",
    "            database_name : Le nom de la base de données dans laquelle sauvegarder l'item\n",
    "        \"\"\"\n",
    "        if self.database_name != None :\n",
    "            d = shelve.open(self.database_name, 'c')\n",
    "            if d.__contains__(self.id) == False:\n",
    "                d[self.id] = self\n",
    "            else : \n",
    "                if self.integrity != d[self.id].integrity :\n",
    "                    d[self.id] = self\n",
    "            d.close()\n",
    "\n",
    "    def checkIntegrity(self):\n",
    "        \"\"\"\"\n",
    "        Permet la vérification de l'exactitude des informations précédement enregistrer par rapport au données actuels\n",
    "\n",
    "        Retour :\n",
    "            Retourne Vrai si les données n'ont pas changé et Faux autrement\n",
    "        \"\"\"\n",
    "        if self.database_name != None :\n",
    "            ret = True\n",
    "            d = shelve.open(self.database_name, 'c')\n",
    "            if d.__contains__(self.id) == False:\n",
    "                ret = False\n",
    "            else : \n",
    "                if self.integrity != d[self.id].integrity :\n",
    "                    ret = False\n",
    "            d.close()\n",
    "            return ret\n",
    "        else :\n",
    "            return False\n",
    "\n",
    "    def save_elastic(self):\n",
    "        if self.elastic_connection != None :\n",
    "            self.elastic_connection.insertion_item(self)"
   ]
  },
  {
   "source": [
    "### Crawler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    nb_crawl_max = 1\n",
    "\n",
    "    def __init__(self, nb_already=0, _elastic_connection = None):\n",
    "        self.nb_already_done = nb_already\n",
    "        if _elastic_connection != None : \n",
    "            self.elastic_tool = _elastic_connection\n",
    "        else : \n",
    "            self.elastic_tool = ElasticTool()\n",
    "\n",
    "    def crawl(self, _link):\n",
    "        if(self.nb_already_done < self.nb_crawl_max):\n",
    "            d = feedparser.parse('%s' % _link)\n",
    "            for post in d.entries:\n",
    "                elem = Item_RSS(post,d.feed,elastic_connection = self.elastic_tool)\n",
    "                for l in elem.all_links:\n",
    "                    c = Crawler(self.nb_already_done + 1, _elastic_connection=self.elastic_tool)\n",
    "                    c.crawl(l['href'])\n",
    "                elem.save_database()"
   ]
  },
  {
   "source": [
    "## TP2 - ElasticSearch\n",
    "### ElasticTool"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticTool:\n",
    "\n",
    "    _es = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._es = self.getConnection()\n",
    "        self.add_all_index()\n",
    "\n",
    "    def getConnection(self, _host = 'localhost', _port=9200):\n",
    "        if self._es == None :\n",
    "            self._es = Elasticsearch([{'host': _host, 'port': _port}])\n",
    "        return self._es\n",
    "\n",
    "    def add_index(self, name_index):\n",
    "        if self._es.indices.exists(index=name_index):\n",
    "            self._es.indices.create(index=name_index, ignore=400)\n",
    "\n",
    "    def add_all_index(self):\n",
    "        self.add_index(\"item_rss\")\n",
    "        self.add_index(\"title\")\n",
    "        self.add_index(\"summary\")\n",
    "        self.add_index(\"description\")\n",
    "        self.add_index(\"links\")\n",
    "        self.add_index(\"source_post\")\n",
    "        self.add_index(\"lang\")\n",
    "        self.add_index(\"date\")\n",
    "        self.add_index(\"target_data\")\n",
    "        self.add_index('integrity')\n",
    "\n",
    "    def delete_index(self, name_index):\n",
    "        self._es.indices.delete(index=name_index, ignore=[400, 404])\n",
    "\n",
    "    def delete_all_index(self):\n",
    "        self.delete_index(\"item_rss\")\n",
    "        self.delete_index(\"title\")\n",
    "        self.delete_index(\"summary\")\n",
    "        self.delete_index(\"description\")\n",
    "        self.delete_index(\"links\")\n",
    "        self.delete_index(\"source_post\")\n",
    "        self.delete_index(\"lang\")\n",
    "        self.delete_index(\"date\")\n",
    "        self.delete_index(\"target_data\")\n",
    "        self.delete_index('integrity')\n",
    "\n",
    "    def insertion_all_items(self, _items):\n",
    "        for i in _items :\n",
    "            self.insertion_item(i)\n",
    "\n",
    "    def insertion_item(self, _item):\n",
    "        \n",
    "        id_title = self.save_title(_item)\n",
    "        id_summary = self.save_summary(_item)\n",
    "        id_description = self.save_description(_item)\n",
    "        id_all_links = self.save_all_links(_item)\n",
    "        id_source_post = self.save_source_post(_item)\n",
    "        id_lang = self.save_lang(_item)\n",
    "        id_date = self.save_date(_item)\n",
    "        id_target_data = False #self.save_target_data(_item)\n",
    "        self.save_item(_item.id, id_title, id_summary, id_description, id_all_links, id_source_post, id_lang, id_date, id_target_data)\n",
    "\n",
    "    def save_item(self, _id, _title, _summary, _description, _all_links, _source_post, _lang, _date, _target_data):\n",
    "        content_body = {}\n",
    "        if _title != False :\n",
    "            content_body['id_title'] = _title\n",
    "        if _summary != False :\n",
    "            content_body['id_summary'] = _summary\n",
    "        if _description != False :\n",
    "            content_body['id_description'] = _description\n",
    "        if _all_links != False :\n",
    "            content_body['id_all_links'] = _all_links\n",
    "        if _source_post != False :\n",
    "            content_body['id_source_post'] = _source_post\n",
    "        if _lang != False :\n",
    "            content_body['id_lang'] = _lang\n",
    "        if _date != False :\n",
    "            content_body['id_date'] = _date\n",
    "        if _target_data != False :\n",
    "            content_body['id_target_data'] = _target_data\n",
    "        self._es.index(index='item_rss', id=_id, body=content_body)\n",
    "\n",
    "    def save_title(self, _item) : \n",
    "        if(_item.title != None) : \n",
    "            content_body = {\n",
    "                'value' : _item.title,\n",
    "                'tags' : _item.title.split(' '),\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"title\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_summary(self, _item):\n",
    "        if _item.summary != None :\n",
    "            content_body = {\n",
    "                'value' : _item.summary,\n",
    "                'tags' : _item.summary.split(' '),\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"summary\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_description(self, _item):\n",
    "        if _item.description != None :\n",
    "            content_body = {\n",
    "                'value' : _item.description,\n",
    "                'tags' : _item.description.split(' '),\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"description\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_link(self, _link, _id):\n",
    "        content_body = {\n",
    "            'value' : _link,\n",
    "            'id_item' : _id\n",
    "        }\n",
    "        return self._es.index(index=\"links\", body=content_body)['_id']\n",
    "\n",
    "    def save_all_links(self,_item):\n",
    "        id_tab_links = []\n",
    "        if(_item.all_links != None):\n",
    "            for l in _item.all_links:\n",
    "                id_tab_links.append(self.save_link(l, _item.id))\n",
    "        return id_tab_links if len(id_tab_links)>0 else False\n",
    "\n",
    "    def save_source_post(self, _item):\n",
    "        if _item.source_post != None :\n",
    "            content_body = {\n",
    "                'value' : _item.source_post,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"source_post\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_lang(self, _item):\n",
    "        if _item.source_post != None :\n",
    "            content_body = {\n",
    "                'value' : _item.lang,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"lang\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_date(self, _item):\n",
    "        if _item.date != None :\n",
    "            content_body = {\n",
    "                'value' : _item.date,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"date\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_target_data(self, _item):\n",
    "        if _item.target_data != None :\n",
    "            content_body = {\n",
    "                'value' : _item.target_data,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"target_data\", body=content_body)['_id']\n",
    "        return False\n",
    "\n",
    "    def save_integrity(self, _item):\n",
    "        if _item.integrity != None :\n",
    "            content_body = {\n",
    "                'value' : _item.integrity,\n",
    "                'id_item' : _item.id\n",
    "            }\n",
    "            return self._es.index(index=\"integrity\", body=content_body)['_id']\n",
    "        return False\n",
    "        \n",
    "    def search_by_tags(self, index_name, tags, size_result=999):\n",
    "        \n",
    "        str_query = ''\n",
    "        maxi = len(tags)\n",
    "        for i in range(maxi):\n",
    "            str_query += 'tags:' + tags[i]\n",
    "            if i < maxi-1:\n",
    "                str_query += ' AND '\n",
    "                \n",
    "        query_body ={\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                    \"query\" : str_query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return self._es.search(index=index_name, body=query_body, size=size_result)\n"
   ]
  },
  {
   "source": [
    "## TP 3 - Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Lancement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cr = Crawler()\n",
    "cr.crawl(\"https://www.lefigaro.fr/rss/figaro_economie.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tags:commerces\ntags:commerces AND tags:rouvrir AND tags:pouvoir\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'took': 3,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 1, 'relation': 'eq'},\n",
       "  'max_score': 8.777697,\n",
       "  'hits': [{'_index': 'description',\n",
       "    '_type': '_doc',\n",
       "    '_id': '_l2IrnUB1UJFcz4jme6d',\n",
       "    '_score': 8.777697,\n",
       "    '_source': {'value': 'Elles demandent aussi de pouvoir rouvrir les commerces «non essentiels» dès le 12 novembre.',\n",
       "     'tags': ['Elles',\n",
       "      'demandent',\n",
       "      'aussi',\n",
       "      'de',\n",
       "      'pouvoir',\n",
       "      'rouvrir',\n",
       "      'les',\n",
       "      'commerces',\n",
       "      '«non',\n",
       "      'essentiels»',\n",
       "      'dès',\n",
       "      'le',\n",
       "      '12',\n",
       "      'novembre.'],\n",
       "     'id_item': '23753b75a744f0cf134c1ca597fad4a705f023a0afc36afa8b92d745'}}]}}"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "elastic_tool = ElasticTool()\n",
    "elastic_tool.search_by_tags('description',['commerces'])\n",
    "elastic_tool.search_by_tags('description', ['commerces', 'rouvrir', 'pouvoir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_tool.delete_all_index()"
   ]
  }
 ]
}